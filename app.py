from flask import Flask, send_from_directory, jsonify
from crawler import RedditCrawler
import os
import threading

app = Flask(__name__)

SAVE_DIR = "data"
SQL_EXPORT = os.path.join(SAVE_DIR, "reddit_data.sql")

crawler = RedditCrawler()

@app.route("/")
def home():
    html = """
    <h2>üìä Reddit SQL Exporter</h2>
    <p>H·ªá th·ªëng t·ª± crawl v√† l∆∞u d·ªØ li·ªáu Reddit v√†o file <b>reddit_data.sql</b>.</p>
    <a href='/download'>‚¨áÔ∏è T·∫£i file SQL</a><br><br>
    <a href='/show'>üëÄ Xem 30 d√≤ng cu·ªëi c·ªßa file SQL</a>
    """
    return html

@app.route("/download")
def download_sql():
    if os.path.exists(SQL_EXPORT):
        return send_from_directory(SAVE_DIR, "reddit_data.sql", as_attachment=True)
    return jsonify({"error": "File SQL ch∆∞a ƒë∆∞·ª£c t·∫°o."}), 404

@app.route("/show")
def show_sql():
    if not os.path.exists(SQL_EXPORT):
        return "<p>‚ö†Ô∏è Ch∆∞a c√≥ file SQL ƒë·ªÉ hi·ªÉn th·ªã.</p>"
    with open(SQL_EXPORT, "r", encoding="utf-8") as f:
        lines = f.readlines()[-30:]
    return "<pre>" + "".join(lines) + "</pre>"

def run_crawler():
    crawler.fetch_users_from_subreddit()

# Ch·∫°y crawler ·ªü thread ri√™ng
threading.Thread(target=run_crawler, daemon=True).start()

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080)
